# :rocket:CreaciÃ³n de sistemas RAG sobre bases de datos vectoriais!

El objetivo del ejercicio es desarrollar un sistema RAG (GeneraciÃ³n Aumentada Recuperada). Este tipo de sistema integra o utiliza el LLM y su propia base de datos para responder mÃ¡s preguntas que el usuario haga.


## ğŸ“‹ GuÃ­a para Configurar y Ejecutar el Modelo Llama 3.2

 #### ğŸ› ï¸ **1. Crear una Red en Docker**

Primero, crea una red personalizada que permita la comunicaciÃ³n entre los servicios involucrados en el proyecto:

    docker network create llama_network

#### ğŸ‹ **2. Iniciar el Contenedor de Ollama**

Levanta el contenedor de Ollama, encargado de gestionar el modelo de lenguaje. Ejecuta este comando para iniciar sin soporte para GPU:

    docker run -d -v llama_data:/root/.ollama -p 11434:11434 --name llama_service --net=llama_network ollama/ollama

#### âœ… **3. Comprobar el Estado del Servicio Ollama**

AsegÃºrate de que Ollama se estÃ¡ ejecutando correctamente ejecutando el siguiente comando:

    curl http://localhost:11434
Si todo estÃ¡ configurado correctamente, deberÃ­as recibir como respuesta:

    Ollama is running

#### ğŸ’» **4. Configurar Open-WebUI**

Open-WebUI proporciona una interfaz visual para gestionar modelos y permitir interacciÃ³n mediante chat.

Inicia el contenedor de Open-WebUI con el siguiente comando:

    docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=http://llama_service:11434 -v webui_data:/app/backend/data --name open_web_ui --net=llama_network --restart always ghcr.io/open-webui/open-webui:main

#### ğŸ“¥ **5. Descargar un Modelo de Lenguaje**

-   ğŸŒ Accede a Open-WebUI desde el navegador.
-   ğŸ” Busca el modelo **Llama 3.2** y descÃ¡rgalo.
-   âœ”ï¸ Verifica que el modelo aparece como instalado en la lista disponible.

**Nota**: AsegÃºrate de mantener activo el contenedor de Ollama para ejecutar cuadernos de trabajo. Open-WebUI solo es necesario para la descarga del modelo.

## âš™ï¸ Configurar el Entorno e Instalar Dependencias
#### ğŸ“¦ **1. Crear y Activar un Entorno Virtual**

Utiliza **Conda** para gestionar un entorno virtual para el proyecto. Ejecuta los siguientes comandos en la terminal:

    conda create --name rag_env python=3.13.1
    conda activate rag_env
    conda install pip
#### ğŸ“š **2. Instalar LibrerÃ­as Necesarias**

Con el entorno activado, instala las dependencias listadas en el archivo `requirements.txt`:

    pip install -r requirements.txt

## ğŸ§  ImplementaciÃ³n de un Sistema RAG
El objetivo principal es desarrollar un sistema **RAG (Retrieve-Augmented Generation)**, que combine un modelo de lenguaje grande (**LLM**) con una base de datos personalizada para responder preguntas fundamentadas en informaciÃ³n previamente almacenada.

#### ğŸ“‚ Apartados del Proyecto

1.  ğŸŒ **RAG en InglÃ©s usando Datos de una PÃ¡gina Web**
    
    -   Crear un sistema que utilice datos de una pÃ¡gina web como fuente de informaciÃ³n.
    -   Almacenar los datos en una base de datos vectorial y procesar las consultas de los usuarios basÃ¡ndose en la informaciÃ³n extraÃ­da.
2.  ğŸ“„ **RAG en EspaÃ±ol a partir de Archivos PDF**
    
    -   Desarrollar un sistema que procese archivos PDF.
    -   Dividir el contenido en fragmentos, almacenarlo en una base de datos vectorial y responder preguntas en espaÃ±ol basÃ¡ndose en dichos datos.
3.  ğŸ–¥ï¸ **DiseÃ±ar una Interfaz GrÃ¡fica (GUI)**
    
    -   Implementar una GUI para interactuar con uno de los sistemas RAG creados.
    -   La interfaz debe ser intuitiva, permitiendo a los usuarios enviar preguntas y recibir respuestas fÃ¡cilmente.
4.  â˜ï¸ **RAG Dockerizado con MongoDB Atlas**
    
    -   Configurar un sistema RAG que use MongoDB Atlas para almacenar y gestionar la base de datos vectorial.
    -   Ofrecer una soluciÃ³n robusta y escalable para manejar consultas y datos.
### ğŸ“ **Notas Finales**

Cada secciÃ³n debe completarse siguiendo las instrucciones especÃ­ficas y asegurÃ¡ndose de cumplir los objetivos del proyecto de forma estructurada y eficiente.
